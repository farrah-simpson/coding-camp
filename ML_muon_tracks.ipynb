{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning using Muon Tracks in CMS  \n",
    "\n",
    "\n",
    "Write code to expand the pseudocode below into an investigation of [muon track data](https://github.com/QuarkNet-HEP/coding-camp/tree/main/data) in the CMS detector using Machine Learning techniques. You may find the textbook Chapter 4 of 'Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow' by O'Reilly helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem  \n",
    "Can we use machine learning to improve our fitting techniques?  \n",
    "\n",
    "## Plan  \n",
    "Use machine learning regression techniques to fit model functions to CMS tracker data for a muon. This is based on the Muon Tracks activity with machine learning application.\n",
    "\n",
    "## Data  \n",
    "For muon track 1, pt = 25 GeV, particle is a muon with q= -1. muon_track_1.csv has 3 rows of header info to ignore for analysis as a pandas dataframe. Data include x,y coordinates of the muon's trajectory but not z. The tracker has a spatial resolution on the order of 0.5 cm due to physical size of the hardware elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038726</td>\n",
       "      <td>-0.015958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.131212</td>\n",
       "      <td>-0.055478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223866</td>\n",
       "      <td>-0.094564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316684</td>\n",
       "      <td>-0.133215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.409664</td>\n",
       "      <td>-0.171429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.038726 -0.015958\n",
       "1  0.131212 -0.055478\n",
       "2  0.223866 -0.094564\n",
       "3  0.316684 -0.133215\n",
       "4  0.409664 -0.171429"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track = pd.read_csv('../data/muon_track_1.csv', skiprows=2)\n",
    "track.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "We will use the function LinearRegression from the Scikit-Learn library to train a linear regression model. Training a model means setting its parameters so that the model best fits the training dataset using a performace measure. This is done by finding parameters in the model that minimizes the Root Mean Square Error or the Mean Square Error by minimizing the (cost) function. \n",
    "\n",
    "The LinearRegression class is based on [scipy.linalg.lstsq()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html) function which calculates the least squares solution to an equation. You can see more details on the function and the format of the input [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)The array must be 2D so we will reshape the data before fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear model to a set of muon tracks in CMS using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = track['x'].values.reshape(-1, 1)\n",
    "Y = track['y'].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#Print the model's coefficient and intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the model's predictions for a new array X_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model Fitting using Stochastic Gradient Descent\n",
    "\n",
    "Gradient Descent is a generic optimization algorithm capable of finding optimal solutions to a wide variety of problems by iteratively changing parameters to minimize a cost function. Gradient Descent measures the local gradient of the error function and goes in the direction of descending gradient. The size of the step is the learning rate. \n",
    "\n",
    "We will use SGDRegressor from the sklearn library to implement machine learning techniques to fit the linear model. SGD stands for Stochastic Gradient Descent: picks a random instance in the training set at every step and computes the gradients based only on that single instance. More details about the function can be found [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "We will perform Linear Regression using SGD for maximum 1000 epochs (max_iter=1000) or until the loss drops by less than 1e-3 during one epoch (tol=1e-3), starting with a learning rate of 0.3 (eta0=0.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.38488234]), array([-0.01331508]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, eta0=1.1, random_state=42)\n",
    "sgd_reg.fit(X,Y.ravel())\n",
    "sgd_params = sgd_reg.coef_, sgd_reg.intercept_\n",
    "sgd_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that determines the learning rate at each iteration is called the learning schedule. If the learning rate is reduced too quickly, you may get stuck in a local minimum or even end up frozen before reaching the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decrease the learning rate to 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase the learning rate to 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "We know that the path of a muon is not a simple straight line. We can use a linear model to fit nonlinear data by adding features to our variable X in order to use linear regression. We can now fit our data to a parabola by adding a second feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-41bb726816ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Fit the data to the new quadratic function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpoly_regg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Now print the coefficients and intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "poly_reg = LinearRegression()\n",
    "\n",
    "#Fit the data to the new quadratic function \n",
    "\n",
    "poly_regg_params = poly_reg.coef_, poly_reg.intercept_\n",
    "\n",
    "#Now print the coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-87b60495a0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plotting the original data and the optimized model (i.e., trendline)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear regression\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msgd_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SGD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoly_regg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpoly_regg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpoly_regg_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"polynomial regg model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47fe7d6a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the models using chi-sq\n",
    "\n",
    "# plotting the original data and the optimized model (i.e., trendline)\n",
    "plt.scatter(track['x'], track['y'], label=\"data\", color='k')\n",
    "plt.plot(track['x'], linear_model(track['x'], regg_params[0][0][0],regg_params[1][0]), label=\"linear regression\",color='red')\n",
    "plt.plot(track['x'], linear_model(track['x'], sgd_params[0],sgd_params[1]), label=\"SGD\",color='blue')\n",
    "plt.plot(track['x'], (poly_regg_params[0][0][1]*np.square(track['x']) + poly_regg_params[0][0][0]*track['x'] + poly_regg_params[1]), label=\"polynomial regg model\",color='black')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "track['linear regg model yvals'] = linear_model(track['x'], regg_params[0][0][0],regg_params[1][0])\n",
    "track['polynomial regg model yvals'] = poly_regg_params[0][0][1]*np.square(track['x']) + poly_regg_params[0][0][0]*track['x'] + poly_regg_params[1][0]\n",
    "\n",
    "track['linear regg model residuals'] = track['y'] - track['linear regg model yvals']\n",
    "track['polynomial regg model residuals'] = track['y'] - track['polynomial regg model yvals']\n",
    "\n",
    "\n",
    "track.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Models\n",
    "\n",
    "So far we have trained models setting its parameters so that the model best fits the training set. If you perform a high-degree polynomial regression, you will fit the training data much better than the Linear Regression. However, fitting to a 300-degree polynomial data will cause the model to try to get as close to the data as possible, overfitting the training data, while the linear model is underfitting the training data. \n",
    "\n",
    "To reduce overfitting, we regularize or constain the model. For instance to regularize a polynomial model, you reduce the number of degrees it has. For a linear model, regularization is done by constraining the weights of the model. \n",
    "\n",
    "Ridge model solves a regression model where the loss function is the linear least squares function. It is a regularized version of Linear Regression. It adds a regularization term to the cost function. This forces the learning algorithm to keep the weights as small as possible during training. The hyperparameter (alpha) controls how much you want to regulatize the model. \n",
    "\n",
    "You can learn more about the model and Ridge Model in the sklearn library [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) \n",
    "\n",
    "We will fit the data to a ridge linear model and Sochastic Average Gradient descent (solver=\"sag\") to a second degree polynomial (degree=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('poly_features', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)), ('std_scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('regul_reg', Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='sag', tol=0.001))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg_sag = Ridge(alpha=1, solver=\"sag\")\n",
    "ridge_reg_sag = Pipeline([\n",
    "                    (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                    (\"std_scaler\", StandardScaler()),\n",
    "                    (\"regul_reg\", ridge_reg_sag),\n",
    "])\n",
    "ridge_reg_sag.fit(X,Y)\n",
    "\n",
    "#Use the Ridge Model to predict result for X = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least Absolute Shrinkage and Selection Operator (Lasso) Regression is another regularized version of Linear Regression. We will now use the [Lasso model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) to fit our data and predict the result when X = 0.5\n",
    "\n",
    "Task: Fit a Lasso linear model with alpha=1. Check which value it predicts for X=[[0.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Lasso from sklearn.linear_model to predict the result for X = 0.5. Set the regularization constant to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have repeated the Muon Tracking exercise to perform a linear fit to the data. We improved our fitting techniques by using polynomial regression. We also introduced two new fitting techniques that use regularization to prevent overfitting our data: the Ridge Model and Lasso Model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

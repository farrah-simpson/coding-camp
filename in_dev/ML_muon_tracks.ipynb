{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa364a11",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning using Muon Tracks in CMS  \n",
    "\n",
    "\n",
    "Write code to expand the pseudocode below into an investigation of [muon track data](https://github.com/QuarkNet-HEP/coding-camp/tree/main/data) in the CMS detector using Machine Learning techniques. You may find the textbook Chapter 4 of 'Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow' by O'Reilly helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef381959",
   "metadata": {},
   "source": [
    "## Problem  \n",
    "Can we use machine learning to improve our fitting techniques?  \n",
    "\n",
    "## Plan  \n",
    "Use machine learning regression techniques to fit model functions to CMS tracker data for a muon. This is based on the Muon Tracks activity with machine learning application.\n",
    "\n",
    "## Data  \n",
    "For muon track 1, pt = 25 GeV, particle is a muon with q= -1. muon_track_1.csv has 3 rows of header info to ignore for analysis as a pandas dataframe. Data include x,y coordinates of the muon's trajectory but not z. The tracker has a spatial resolution on the order of 0.5 cm due to physical size of the hardware elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6580100",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = pd.read_csv('https://github.com/QuarkNet-HEP/coding-camp/raw/main/data/muon_track_1.csv', skiprows=2)\n",
    "track.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129769f",
   "metadata": {},
   "source": [
    "## Analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e737b87",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "We will use the function [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) from the Scikit-Learn library to train a linear regression model. Training a model means setting its parameters so that the model best fits the training dataset using a performace measure. This is done by finding parameters in the model that minimizes the Root Mean Square Error or the Mean Square Error by minimizing the (cost) function. \n",
    "\n",
    "The LinearRegression class is based on [scipy.linalg.lstsq()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html) function which calculates the least squares solution to an equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model to a set of muon tracks in CMS using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# The array must be 2D so we will reshape the data before fitting\n",
    "X = track['x'].values.reshape(-1, 1)\n",
    "Y = track['y'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d108fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model and name it lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98337cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model's coefficient and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e03b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions for a new range of values called X_new\n",
    "X_new = np.array([.25, .5, .75, 1]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad913e",
   "metadata": {},
   "source": [
    "### Linear Model Fitting using Stochastic Gradient Descent\n",
    "\n",
    "Gradient Descent is a generic optimization algorithm capable of finding optimal solutions to a wide variety of problems by iteratively changing parameters to minimize a cost function. Gradient Descent measures the local gradient of the error function and goes in the direction of descending gradient. The size of the step is the learning rate. \n",
    "\n",
    "We will use SGDRegressor from the sklearn library to implement machine learning techniques to fit the linear model. SGD stands for Stochastic Gradient Descent: picks a random instance in the training set at every step and computes the gradients based only on that single instance. More details about the function can be found [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "We will perform Linear Regression using SGD for maximum 1000 epochs (max_iter=1000) or until the loss drops by less than 1e-3 during one epoch (tol=1e-3), starting with a learning rate of 0.3 (eta0=0.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, eta0=0.3, random_state=42)\n",
    "sgd_reg.fit(X,Y.ravel())\n",
    "sgd_params = sgd_reg.coef_, sgd_reg.intercept_\n",
    "sgd_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172995ce",
   "metadata": {},
   "source": [
    "The function that determines the learning rate at each iteration is called the learning schedule. If the learning rate is reduced too quickly, you may get stuck in a local minimum or even end up frozen before reaching the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease the learning rate to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the learning rate to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfe49af",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "We know that the path of a muon is not a simple straight line. We can use a linear model to fit nonlinear data by adding features to our variable X in order to use linear regression. We can now fit our data to a parabola by adding a second feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9246f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the transformed array to make a new linear model and name it poly_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5df953",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_params = poly_reg.coef_, poly_reg.intercept_\n",
    "\n",
    "# what quantity does this print?\n",
    "poly_reg_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647312df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the original data and the optimized models (i.e., trendlines)\n",
    "plt.scatter(track['x'], track['y'], label=\"data\", color='k')\n",
    "plt.plot(track['x'], linear_model(track['x'], lin_reg_params[0][0][0],lin_reg_params[1][0]), label=\"linear regression\",color='red')\n",
    "plt.plot(track['x'], linear_model(track['x'], sgd_params[0],sgd_params[1]), label=\"SGD\",color='blue')\n",
    "plt.plot(track['x'], (poly_reg_params[0][0][1]*np.square(track['x']) + poly_reg_params[0][0][0]*track['x'] + poly_reg_params[1]), label=\"polynomial regg model\",color='black')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df53d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the models using chi-sq or RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17b1a5",
   "metadata": {},
   "source": [
    "### Regularized Models\n",
    "\n",
    "So far we have trained models setting its parameters so that the model best fits the training set. If you perform a high-degree polynomial regression, you will fit the training data much better than the Linear Regression. However, fitting to a 300-degree polynomial data will cause the model to try to get as close to the data as possible, overfitting the training data, while the linear model is underfitting the training data. \n",
    "\n",
    "To reduce overfitting, we regularize or constain the model. For instance to regularize a polynomial model, you reduce the number of degrees it has. For a linear model, regularization is done by constraining the weights of the model. \n",
    "\n",
    "Ridge model solves a regression model where the loss function is the linear least squares function. It is a regularized version of Linear Regression. It adds a regularization term to the cost function. This forces the learning algorithm to keep the weights as small as possible during training. The hyperparameter (alpha) controls how much you want to regulatize the model. \n",
    "\n",
    "You can learn more about the model and Ridge Model in the sklearn library [here.](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) \n",
    "\n",
    "We will fit the data to a ridge linear model and Sochastic Average Gradient descent (solver=\"sag\") to a second degree polynomial (degree=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg_sag = Ridge(alpha=1, solver=\"sag\")\n",
    "ridge_reg_sag = Pipeline([\n",
    "                    (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                    (\"std_scaler\", StandardScaler()),\n",
    "                    (\"regul_reg\", ridge_reg_sag),\n",
    "])\n",
    "ridge_reg_sag.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the Ridge Model prediction to your earlier lin_reg prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e248e",
   "metadata": {},
   "source": [
    "[Least Absolute Shrinkage and Selection Operator (Lasso) Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) is another regularized version of Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80460293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the Lasso regression prediction to your earlier predictions. Set the regularization constant to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465a4b8",
   "metadata": {},
   "source": [
    "## Conclusion  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c0a69",
   "metadata": {},
   "source": [
    "We have repeated the Muon Tracking exercise to perform a linear fit to the data. We improved our fitting techniques by using polynomial regression. We also introduced two new fitting techniques that use regularization to prevent overfitting our data: the Ridge Model and Lasso Model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
